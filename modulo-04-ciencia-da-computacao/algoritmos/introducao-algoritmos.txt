# O que √© um algoritmo?

Uma vez que usamos essa palavra com frequ√™ncia, √© preciso que tenhamos a defini√ß√£o bem n√≠tida para esse conceito, de modo a garantir que estamos partindo do mesmo ponto quando falamos de Complexidade Algor√≠tmica.

‚ÄúInformalmente, um algoritmo √© qualquer procedimento computacional bem definido que toma algum valor ou conjunto de valores como entrada e produz algum valor ou conjunto de valores como sa√≠da. Portanto, um algoritmo √© uma sequ√™ncia de etapas computacionais que transformam a entrada na sa√≠da‚Äù (CLRS - Introduction to Algorithms)

‚ÄúUm algoritmo √© um conjunto de instru√ß√µes que realizam uma tarefa.‚Äù (BHARGAVA, ADITYA Y. - Entendendo Algoritmos)

Basicamente, um algoritmo √© uma sequ√™ncia l√≥gica de passos bem definida (entrada, processamento e sa√≠da) que realiza determinada tarefa.

Pode parecer que usamos algoritmos somente para resolver problemas computacionais, entretanto, tamb√©m os utilizamos no nosso dia a dia! Observe alguns exemplos a seguir:

Se vestir;
Assar um bolo;
Preparar um sandu√≠che;
Trocar uma l√¢mpada;
Vejamos na anima√ß√£o abaixo como seria um exemplo de algoritmo para se vestir:


Pois bem! Apesar de existirem diversas formas de realizarmos uma tarefa, nem sempre a forma que escolhemos nos retornar√° o resultado esperado. Com isso, um algoritmo pode ou n√£o ser correto, podemos consider√°-lo correto se, e somente se, nos entrega a sa√≠da esperada para todas as entradas, isto √©, ele resolve aquele problema.

‚ö†Ô∏è Aviso: Algoritmos incorretos n√£o t√™m o comportamento de resolver um problema, e s√£o utilizados apenas quando √© poss√≠vel controlar bem sua taxa de erro; algo que √© raro, entretanto devemos mencionar isso a t√≠tulo de conhecimento.

Agora que estamos na mesma p√°gina em rela√ß√£o aos conceitos de algoritmo e algoritmos corretos (ou corretude), vamos compreender o que √© a Complexidade Algor√≠tmica.

* Para come√ßar, observe o algoritmo abaixo:

EX:

def sum_array(numbers):
    sum = 0
    for number in numbers:
        sum += number

    return sum
    
Anota a√≠ üñä: A fun√ß√£o sum_array recebe um array de n√∫meros, percorre-o e executa a soma de cada um de seus valores (number), retornando a soma de todos os n√∫meros pertencentes ao array.

Voc√™ consegue imaginar quanto tempo esse c√≥digo vai demorar em sua execu√ß√£o?

Resposta: ‚ÄúIsso depende de muitos fatores‚Äù. Afinal, o tempo de execu√ß√£o depende da m√°quina, do que est√° rodando nela, dos recursos etc. N√£o conseguimos dizer isso apenas ao olhar para o c√≥digo.

Por√©m, vamos supor que estamos falando de uma m√°quina padr√£o e sem mais nada rodando nela. Quanto tempo voc√™ imagina que o algoritmo vai demorar para executar? Um segundo? Dez segundos?

Temos mais um ‚Äúdepende‚Äù aqui, n√£o √© mesmo? O tempo de execu√ß√£o depende do tamanho do array passado por par√¢metro! Quanto maior o tamanho dele, mais tempo o algoritmo gastar√° em sua execu√ß√£o.

Dito isso, n√£o sabemos quanto tempo o algoritmo vai demorar para executar, pois vai depender de in√∫meros fatores que v√£o al√©m do nosso controle. Mas, uma coisa podemos afirmar: O tempo de execu√ß√£o dele √© proporcional ao tamanho do dado de entrada. Por exemplo:

EX:

# def sum_array(numbers):
  # ...

# Suponha que, para o array abaixo, o tempo de execu√ß√£o seja `n`
sum_array(array_com_dez_mil_numeros)

# Nesse caso, aqui o tempo de execu√ß√£o vai ser `10 * n`, ou `10n`, j√° que o array √© dez vezes maior que o anterior
sum_array(array_com_cem_mil_numeros)

# J√° esse √© dez mil vezes maior que o primeiro, ent√£o esse aqui executa em `100n`
sum_array(array_com_um_milh√£o_de_numeros)

Note que conforme aumentamos o valor da entrada, o tempo de execu√ß√£o do algoritmo aumenta proporcionalmente, de acordo com uma taxa.

√â isso que chamamos de complexidade: A taxa de crescimento do tempo de execu√ß√£o de um algoritmo; quanto maior √© essa taxa, maior √© seu tempo de execu√ß√£o e, portanto, maior sua complexidade.

No exemplo anterior, os valores de entrada podem variar, mas as propor√ß√µes n√£o: Um aumento no tamanho da entrada aumenta o tempo de execu√ß√£o na mesma propor√ß√£o.

Na medida em que o tamanho da entrada cresce, o tempo de execu√ß√£o cresce na mesma propor√ß√£o
Na medida em que o tamanho da entrada cresce, o tempo de execu√ß√£o cresce na mesma propor√ß√£o

Podemos dizer, em suma, que a Ordem de Complexidade nada mais √© do que a representa√ß√£o dessa propor√ß√£o (ou taxa) de crescimento. Dado que o algoritmo √© linearmente proporcional ao tempo de execu√ß√£o, dizemos que este √© um algoritmo linear.

Anota a√≠ üñä: A Ordem de Complexidade nada mais √© do que a representa√ß√£o dessa propor√ß√£o (ou taxa) de crescimento. Dado que o algoritmo √© linearmente proporcional ao tempo de execu√ß√£o, dizemos que este √© um algoritmo linear.

A fun√ß√£o matem√°tica que representa uma rela√ß√£o linear √© f(n) = n e a nota√ß√£o de Ordem de Complexidade para representar a taxa de crescimento do tempo de execu√ß√£o de um algoritmo √© dada por O(n), onde o n representa a quantidade de opera√ß√µes que o algoritmo vai realizar.

‚ö†Ô∏è Aviso: A partir de agora, sempre que falarmos sobre a Ordem de Complexidade n√£o iremos nos referir ao tempo em segundos que um algoritmo leva para ser executado, mas sim a quantidade de opera√ß√µes que ele realiza. üôÇ

A Ordem de Complexidade pode ser chamada, tamb√©m, de Complexidade Assint√≥tica.


# Complexidade de tempo e de espa√ßo:

Anteriormente, dissemos que a complexidade de um algoritmo representa o crescimento de seu tempo de execu√ß√£o em fun√ß√£o de uma taxa, a quantidade de opera√ß√µes que ele realiza. Por√©m, quando falamos em complexidade, n√£o analisamos apenas o tempo, analisamos tamb√©m o espa√ßo gasto. Vejamos como isso funciona.

Observe o algoritmo a seguir:

EX:

def squared_array(numbers):
    array_of_squares = []
    for number in numbers:
        array_of_squares.append(number * number)

    return array_of_squares
    
Esse algoritmo recebe um array de n√∫meros, percorre esse array e retorna um novo com os n√∫meros ao quadrado. Ou seja, ele passa por todos os elementos desse array. Isso significa que se houver 10 n√∫meros na entrada de dados,por exemplo, ser√£o realizadas 10 opera√ß√µes; se houver 100 ser√£o realizadas 100 opera√ß√µes. O que isso representa em termos de complexidade?

Em rela√ß√£o √† Complexidade de Tempo, temos aqui uma taxa de crescimento linear, uma vez que o aumento no tamanho do array faz crescer proporcionalmente o tempo gasto na execu√ß√£o do algoritmo. Sendo assim, podemos afirmar que a Complexidade de Tempo aqui √© O(n), chamada geralmente tempo linear (Lembre-se que O faz refer√™ncia aqui a ordem de complexidade, enquanto (n) representa a f√≥rmula matem√°tica que diz sobre a taxa de crescimento do n√∫mero de opera√ß√µes).

‚ÄúE quanto √† Complexidade de Espa√ßo?‚Äù ü§î

Bem, como sabemos, esse algoritmo vai sempre nos retornar um array com o mesmo tamanho da entrada de dados, pois ele sempre devolve um novo arraycom todos os n√∫meros de entrada ao quadrado: se entrar um array de 10 n√∫meros, sair√° um de 10; se entrar um de 100, sair√° um de 100 e assim sucessivamente. Desse modo, conforme a entrada cresce, a sa√≠da tamb√©m cresce e, consequentemente, o espa√ßo ocupado por ela, o que implica dizer que sua Complexidade de Espa√ßo √© dada por O(n).

Bora para mais um exemplo!

Recorde-se do algoritmo mencionado na se√ß√£o passada, da fun√ß√£o sum_array. Naquele caso, a Complexidade de Tempo tamb√©m era O(n), j√° que o tempo de execu√ß√£o crescia linearmente.

Mas e sua complexidade de espa√ßo? ü§î

No caso de sum_array, mesmo que a entrada de dados fosse crescendo, sua sa√≠da nunca ocuparia mais espa√ßo, pois o retorno era sempre um n√∫mero s√≥. Sendo assim, sua Complexidade de Espa√ßo era constante e pode ser representada pela nota√ß√£o O(1).

Para finalizar, um ponto importante que deve ser ressaltado √© que quando calculamos a complexidade de espa√ßo n√£o levamos em considera√ß√£o o espa√ßo ocupado pela entrada, uma vez que o tamanho da entrada n√£o √© algo que podemos, com nosso algoritmo, influenciar.

Anota a√≠ üñä: Se falamos em ordem de complexidade sem especificar se √© de tempo ou de mem√≥ria, assuma que √© de tempo!


# Complexidade quadr√°tica:

N√≥s j√° compreendemos o que √© e qual a nota√ß√£o que representa a Complexidade Algor√≠tmica. A partir de agora, vamos ver que, dependendo da forma como um algoritmo √© escrito, seu tempo de execu√ß√£o vai ser alterado de acordo com diferentes taxas de crescimento.

Nesta e nas pr√≥ximas se√ß√µes veremos como o ‚Äútempo de execu√ß√£o dos algoritmos cresce a taxas diferentes‚Äù (BHARGAVA, ADITYA Y.).

Observe o algoritmo abaixo:

EX:

# Os arrays t√™m sempre o mesmo tamanho
def multiply_arrays(array1, array2):
    result = []
    for number1 in array1:
        for number2 in array2:
            result.append(number1 + number2)

    return result
    
No algoritmo acima, s√£o recebidos dois arrays de tamanhos iguais e √© retornado um novo array, cujos elementos s√£o resultado da soma de cada um dos elementos do array1 com todos os elementos do array2.

Qual seria a taxa de crescimento do tempo de execu√ß√£o desse algoritmo?ü§î

Para cada n√∫mero do array1 ser somado com todos os n√∫meros contidos no array2, √© necess√°rio que o segundo seja percorrido por inteiro.

Isso significa que para array1 e array2 com duas posi√ß√µes, ser√£o necess√°rias 4 itera√ß√µes (ou opera√ß√µes), para o algoritmo concluir sua execu√ß√£o. Se cada uma das entradas tiver 3 elementos, ser√£o necess√°rias 9 opera√ß√µes para a conclus√£o da execu√ß√£o e assim sucessivamente.

Rode o exemplo abaixo para conferir:

EX:

def multiply_arrays(array1, array2):
    result = []
    number_of_iterations = 0

    for number1 in array1:
        print(f'Array 1: {number1}')
        for number2 in array2:
            print(f'Array 2: {number2}')
            result.append(number1 * number2)
            number_of_iterations += 1

    print(f'{number_of_iterations} itera√ß√µes!')
    return result


meu_array = [1, 2, 3, 4, 5]

multiply_arrays(meu_array, meu_array)

Para o exemplo acima, no qual as duas entradas continham 5 elementos, foram necess√°rias 25 opera√ß√µes para obtermos o resultado final!

Anota a√≠ üñä: conforme aumentamos o tamanho dos arrays de entrada, o n√∫mero de opera√ß√µes para a execu√ß√£o do algoritmo cresce ao quadrado. Isso significa que, para entradas de tamanho n, a quantidade de opera√ß√µes para executar o algoritmo √© de n¬≤. Sendo assim, a complexidade desse algoritmo √© dada por O(n¬≤) e a chamamos de Complexidade Quadr√°tica.


# Comparando complexidades:

A Ordem de Complexidade diz respeito √† taxa de crescimento do tempo de execu√ß√£o (ou espa√ßo de mem√≥ria ocupado) de um algoritmo, na medida em que aumentamos o tamanho da sua entrada;

Uma complexidade √© O(1) (constante), quando o tempo de execu√ß√£o do algoritmo independe do tamanho da entrada;

Uma complexidade √© O(n) (linear) quando a taxa de crescimento em seu tempo de execu√ß√£o √© linear: se aumentamos a entrada em 2 vezes, aumentamos o tempo de execu√ß√£o em 2 vezes;

Uma complexidade √© O(n¬≤) (quadr√°tica) quando a taxa de crescimento do tempo de execu√ß√£o do algoritmo √© quadr√°tica: se aumentamos a entrada em 2 vezes, aumentamos o tempo de execu√ß√£o em 4 (ou 2¬≤) vezes;

Uma complexidade √© O(n¬≥) (c√∫bica) quando a taxa de crescimento do tempo de execu√ß√£o do algoritmo √© c√∫bica: se aumentamos a entrada em 2 vezes, aumentamos o tempo de execu√ß√£o em 8 (2¬≥) vezes.

Vamos com calma para os n√∫meros n√£o confundirem!
Vamos com calma para os n√∫meros n√£o confundirem!
Falamos aqui de algoritmos O(n), O(n¬≤) e at√© de O(n¬≥). Mas, para ilustrar melhor a matem√°tica dos algoritmos, vamos mostrar o que eles significam de outra forma.

Para exemplificar, vamos pensar do seguinte modo: para um algoritmo linear, com n = 1000, teremos mil opera√ß√µes a serem realizadas. Quando o algoritmo √© O(n¬≤), um n = 1000 gera um milh√£o de opera√ß√µes (ou n¬≤ de opera√ß√µes). Essa mesma quantidade (um milh√£o) para O(n¬≥), se atinge com n = 100.

Est√° entendendo como alguns algoritmos podem ficar rapidamente invi√°veis de se executar? Por isso, compreender a taxa de crescimento de um algoritmo √© t√£o importante!


# Complexidade Logar√≠tmica:

Agora, vamos entender o que √© a Complexidade Logar√≠tmica. Mas, antes disso, √© preciso deixar n√≠tido que, apesar do termo potencialmente assustador, a Complexidade Logar√≠tmica n√£o exige c√°lculos matem√°ticos complicados para ser entendida. üôÇ

Representado pela nota√ß√£o O(log n), um algoritmo logar√≠tmico tem uma altera√ß√£o na taxa de execu√ß√£o que, geralmente, reduz pela metade o tempo de finaliza√ß√£o das itera√ß√µes ao reduzir pela metade o tamanho do input a cada itera√ß√£o.

Na matem√°tica, logaritmo √© a opera√ß√£o inversa da exponencial. O logaritmo de um n√∫mero √© o expoente ao qual um valor base deve ser elevado para produzir este n√∫mero. Por exemplo, o logaritmo de 1000 na base 10 √© igual a 3, porque 10 elevado ao cubo √© igual a 1000.

Vamos refletir sobre isso:

Suponha que temos um algoritmo cuja entrada n √© igual a 4, se tivermos um algoritmo O(log n) a ser executado com essa entrada, teremos que fazer apenas 2 opera√ß√µes para execut√°-lo, pois log‚ÇÇn (l√™-se: ‚Äúlog de n na base 2‚Äù) √© igual a 2. Se a nossa entrada fosse o dobro, ou seja, 8 ter√≠amos que realizar apenas 3 opera√ß√µes para chegar ao fim da execu√ß√£o. Ao dobrar o valor da entrada novamente, com n igual a 16, ter√≠amos que realizar apenas 4 opera√ß√µes (lg‚ÇÇn_ √© igual a 4) e assim sucessivamente.

Anota a√≠ üñä: O n√∫mero de opera√ß√µes para executar o algoritmo logar√≠tmico tem uma rela√ß√£o inversa ao tamanho da entrada: quanto maior ela √©, menor o n√∫mero de opera√ß√µes e, consequentemente, menor o tempo para a execu√ß√£o do algoritmo!

Voc√™ pode estar se perguntando: ‚ÄúMas como √© poss√≠vel criar um algoritmo com essa Ordem de Complexidade?‚Äùü§î

No exemplo a seguir, temos um algoritmo de busca bin√°ria que entenderemos em detalhes mais adiante. Por ora, basta compreender que esse algoritmo representa uma complexidade O(log n).

Suponha que vamos criar um algoritmo de lista telef√¥nica. Temos uma lista de nomes de tamanho n, ordenada em ordem alfab√©tica, e um nome x; devemos encontrar o n√∫mero de telefone da pessoa passada na entrada.

Rel√≠quia de um passado remoto
Rel√≠quia de um passado remoto.
Suponha que vamos procurar pelo nome Tintim.Como faremos isso?

Buscar na p√°gina (ou posi√ß√£o) da lista que tenha nomes come√ßando com a letra T;
Escolher uma p√°gina aleat√≥ria da lista para abrir;
Percebemos que ca√≠mos na posi√ß√£o da letra M;
Como M < T, na ordem alfab√©tica, ent√£o, devemos avan√ßar algumas posi√ß√µes para encontrar o T;
Ent√£o, escolhemos uma p√°gina que est√° mais adiante;
Percebemos que ca√≠mos na posi√ß√£o da letra V;
Como V > T, na ordem alfab√©tica, ent√£o devemos voltar alguns posi√ß√µes;
Vamos repetimos esse processo at√© encontrarmos o nome desejado.
Haveria outra forma de fazer essa pesquisa na lista telef√¥nica? Sim! N√≥s poder√≠amos passar por cada p√°gina, da letra A at√© a letra T para encontrar Tintim. Por√©m, o n√∫mero de opera√ß√µes necess√°rias para realizar isso seria muito maior do que aquele que usamos no exemplo acima!

Perceba o seguinte: o nosso alfabeto tem 26 letras e a letra T est√° na posi√ß√£o 20 dele. Se segu√≠ssemos o algoritmo de busca sequencial, passando sequencialmente pelas letras de A √† T, ter√≠amos que realizar 20 opera√ß√µes para encontrar o que est√°vamos procurando. Mas, se us√°ssemos o algoritmo de busca bin√°ria, que criamos acima, poder√≠amos resolver facilmente o problema de encontrar a letra T utilizando menos da metade das opera√ß√µes que uma busca sequencial demanda. Ou seja, poder√≠amos facilmente encontrar a letra T na lista telef√¥nica com 10 ou menos passos, obtendo, assim, um algoritmo de complexidade O(log n) para resolver o problema.

Para entender melhor a diferen√ßa entre um algoritmo de busca bin√°ria, logar√≠tmico, com um de busca sequencial, que √© linear, observe o gif abaixo.

binary-and-linear-search-animations
Agora que j√° passamos pelo conceito de Complexidade Logar√≠tmica, vejamos o algoritmo de busca bin√°ria abaixo.

De olho na dicaüëÄ: √© altamente recomendado que voc√™ rode na sua m√°quina para entender melhor como funciona):

EX:

# A estrutura deve estar ordenada para que a busca bin√°ria funcione
def binary_search(numbers, target):
    # definir os √≠ndices
    start = 0
    end = len(numbers) - 1

    while start <= end: # os √≠ndices podem ser no m√°ximo iguais, o in√≠cio n√£o pode ultrapassar o fim
        mid = (start + end) // 2 # encontro o meio

        if numbers[mid] == target: # se o elemento do meio for o alvo, devolve a posi√ß√£o do meio
            return mid
        
        if target < numbers[mid]: # se o elemento for menor, atualiza o √≠ndice do fim
            end = mid - 1
        else: # caso contr√°rio, atualiza o √≠ndice do inicio
            start = mid + 1
    
    return -1 # N√£o encontrou? Retorna -1

numbers = [2, 3, 4, 10, 40]
target = 40

result = binary_search(numbers, target)
print(f"Elemento encontrado na posi√ß√£o: {result}")

Observe como, a cada itera√ß√£o, o algoritmo de busca bin√°ria corta o problema pela metade:

primeiro ele ‚Äúcorta‚Äù a lista em dois e pega o elemento do meio.

Depois ele ‚Äúcaminha‚Äù para o lado no elemento que procura esta e ‚Äúcorta‚Äù este lado novamente pela metade.

Anota a√≠ üñä: Quando cortamos a entrada pela metade, a cada itera√ß√£o, temos um padr√£o que segue a fun√ß√£o matem√°tica de logaritmo na base dois! Assim, nosso algoritmo √© O(log n).

Um logaritmo em base 2 representa o n√∫mero de vezes que um valor deve ser dividido pela metade para obter 1.

Dessa forma, sem precisarmos nos aprofundar na matem√°tica, conseguimos calcular a ordem de complexidade de um algoritmo deste tipo: Quando a entrada √© cortada pela metade a cada itera√ß√£o temos um comportamento logar√≠tmico!


# Analisando algoritmos com v√°rias estruturas de repeti√ß√£o:

Agora que j√° sabemos analisar a Ordem de Complexidade, vamos para alguns algoritmos.

Observe o algoritmo o abaixo:

EX:

def calculations(n):
    number1 = 0
    for n1 in range(n):
        number1 += n1

    number2 = 0
    for n1 in range(n):
       for n2 in range(n):
            number2 += n1 + n2

    number3 = 0
    for n1 in range(n):
       for n2 in range(n):
           for n3 in range(n):
               number3 += n1 + n2 + n3

    return number1, number2, number3

n1, n2, n3 = calculations(100)
print(f'{n1}, {n2}, {n3}')

Esse algoritmo tem tr√™s estruturas de repeti√ß√£o evidentes: uma linear, uma quadr√°tica e uma c√∫bica.

Qual √© a Ordem de Complexidade dele? ü§î

Resposta: A rigor, ela seria O(n + n¬≤ + n¬≥).

De olho na dicaüëÄ: Se os loops est√£o aninhados voc√™ os multiplica, e se est√£o paralelos voc√™ os soma.

Podemos pensar em alguns outros exemplos:

Um algoritmo de busca bin√°ria que roda tr√™s vezes teria O(3 * log n) de complexidade;

Um algoritmo que roda uma busca bin√°ria num array de tamanho n para cada elemento de um array de tamanho m teria O(m * log n) de complexidade.

No entanto, geralmente simplificam-se essas nota√ß√µes. Estamos vendo, ao longo dos nossos estudos, que ordens de complexidade diferentes, para entradas grandes, t√™m valores absurdamente diferentes.

Imagine escrever O(n! + log(n)). Ora, para uma entrada de tamanho 8 esse n√∫mero seria O(40320 + 3). Observe como o componente fatorial da equa√ß√£o, n! = 40320, domina completamente a ordem de complexidade. Nesse cen√°rio, dizemos que a complexidade menor √© desprez√≠vel e, ent√£o, a omitimos.

Anota a√≠ üñä: Para valores grandes, dizer a maior ordem de complexidade do conjunto j√° basta para uma boa an√°lise. Sendo assim, ao analisar v√°rias estruturas de repeti√ß√£o em paralelo, responda somente com o valor da estrutura que tiver maior ordem de complexidade na hora de fazer a sua an√°lise.


# Melhor caso, pior caso e caso m√©dio:

H√° um √∫ltimo conceito importante para aprendermos aqui, antes de passarmos para a aula ao vivo e os exerc√≠cios!

Voc√™ ver√° mais para frente durante seu aprendizado aqui na Trybe, os termos ‚Äúmelhor caso‚Äù, ‚Äúpior caso‚Äù e ‚Äúcaso m√©dio‚Äù.

Eles significam o seguinte: ‚ÄúA depender da minha entrada, o meu algoritmo pode executar em O(1) ou O(n)‚Äú. Por exemplo, pense na busca sequencial:

EX:

def linear_search(numbers, target):
    n = len(numbers) # N ser√° a quantidade de elementos da lista
    for index in range(0, n): # vamos iterar a lista completa
        if numbers[index] == target: # se encontrar o elemento alvo, retorne a posi√ß√£o
            return index

    return -1 # N√£o encontrou? Retorne -1


print(linear_search([1, 2, 3], 2))  # sa√≠da: 1
print(linear_search([1, 2, 3], 4))  # sa√≠da: -1
Dizemos que, para entradas muito grandes, esse algoritmo √© O(n).

O que acontece, por√©m, caso tenhamos sorte e o n√∫mero que procuramos seja o primeiro do array?ü§î

Resposta: Nesse caso, mesmo para uma entrada infinita, nossa complexidade ser√° O(1). Esse √© o melhor caso desse algoritmo. De forma an√°loga, o pior caso √© o n√∫mero ser o √∫ltimo elemento do array, ou seja O(n).

Voc√™ pode estar se perguntando: ‚ÄúE o caso m√©dio‚Äù? ü§î

Resposta: Seria algo como O(n * 1/2), por exemplo. Nesse caso, o n√∫mero que procuramos est√° no meio da lista. Mas, para entradas muito grandes, aprendemos a desprezar os n√∫meros menos relevantes da soma, ent√£o, podemos simplificar e dizer que o caso m√©dio √© O(n) tamb√©m.

Diferentes algoritmos t√™m diferentes cen√°rios de melhor caso, pior caso e caso m√©dio. Veremos v√°rios exemplos disso ao longo das pr√≥ximas se√ß√µes.


# Concluindo:

Hoje conceituamos algoritmo como uma s√©rie de passos para resolver um problema e vimos que existem algoritmos corretos e n√£o corretos.

Aprendemos que podemos dizer qual a Ordem de Complexidade de algoritmos, e que essa √© uma forma de analis√°-los quanto √† taxa de crescimento de tempo de execu√ß√£o, ou de consumo de mem√≥ria, para seus valores de entrada e sa√≠da; sendo que essa an√°lise pode ser feita para quaisquer linguagem e paradigma.

As complexidades que estudamos foram:

Constantes: O(1);

Logar√≠tmicos: O(log n);

Linear: O(n);

Quadr√°ticos: O(n¬≤);

C√∫bicos: O(n¬≥);

Exponencial: O(2‚Åø);

Fatorial: O(n!).

Vimos tamb√©m que, a depender do algoritmo, essas an√°lises podem ser combinadas, como por exemplo num algoritmo O(n log n). Al√©m disso, aprendemos que problemas que n√£o t√™m solu√ß√£o conhecida em tempo polinomial, e que podem ser resolvidos apenas com for√ßa bruta, com complexidades exponencial ou fatorial, s√£o chamados NP Completo.

Comparamos algoritmos com v√°rias estruturas de repeti√ß√£o diferentes e percebemos que devemos sempre considerar a maior Ordem de Complexidade poss√≠vel para represent√°-los e desprezar as demais na nossa nota√ß√£o.

E, por fim, vimos que algoritmos podem ter diferentes ordens de complexidade para seu melhor caso, pior caso e caso m√©dio.
